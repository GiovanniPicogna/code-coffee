\documentclass{aa}
\usepackage{showyourwork}
\usepackage{graphicx}
\usepackage{txfonts}
\usepackage{listings}
\usepackage{subcaption}         % necessary for continued figures, example in section 3
                                % and appendix
\usepackage{lscape}             % to rotate a single page table, example in appendix.
                                % For landscape tables, see the longtable examples.
\usepackage{placeins}           % useful with \FloatBarrier, to keep 
                                % onecolumn floats from drifting to the next section

% -- Loading the code block package:
\setlength{\parindent}{8pt}
\usepackage{indentfirst}% -- Defining colors:
\definecolor{codegreen}{rgb}{0,0.6,0}
\definecolor{codegray}{rgb}{0.5,0.5,0.5}
\definecolor{codepurple}{rgb}{0.58,0,0.82}
\definecolor{backcolour}{rgb}{0.95,0.95,0.92}% Definig a custom style:
\definecolor{navyblue}{rgb}{0.0, 0.0, 0.5}
\lstdefinestyle{mystyle}{
    backgroundcolor=\color{backcolour},   
    commentstyle=\color{codepurple},
    keywordstyle=\color{navyblue},
    numberstyle=\tiny\color{codegray},
    stringstyle=\color{codepurple},
    basicstyle=\ttfamily\footnotesize\bfseries,
    breakatwhitespace=false,         
    breaklines=true,                 
    captionpos=t,                    
    keepspaces=true,                 
    numbers=left,                    
    numbersep=5pt,                  
    showspaces=false,                
    showstringspaces=false,
    showtabs=false,                  
    tabsize=2
}% -- Setting up the custom style:

\lstset{style=mystyle}

\begin{document}

\title{\showyourwork for open science}

\subtitle{Test cases}

\author{Giovanni Picogna}

\institute{Universit\"ats-Sternwarte, Ludwig-Maximilians-Universit\"at M\"unchen, Scheinerstr. 1, M\"unchen, 81679, Bayern, Germany\\
             \email{picogna@usm.lmu.de}}

\date{Received 14 July 2025 / Accepted 14 July 2025}

\abstract {} {I provide some easy to follow instructions to set-up your first \showyourwork project}
{This is not at all a complete guide, for which I point the readers at the well written documentation on https://show-your.work/}
{}{}{}

\keywords{open science}

\maketitle 

% Main body with filler text
\section{Installation}
\label{sec:intro}
\showyourwork requires Python <3.11, >=3.8 in the current development version. We can start by creating a conda environment with python 3.10
  \begin{lstlisting}[language=bash]
    conda create -n python310 python=3.10 anaconda
  \end{lstlisting}
activate it
  \begin{lstlisting}[language=bash]
    conda activate python310
  \end{lstlisting}
and install the development version from github
  \begin{lstlisting}[language=bash]
    pip install git+https://github.com/showyourwork/showyourwork
  \end{lstlisting}

\section{First paper}
\subsection{Local build}
In order to set up your first paper you need to run
  \begin{lstlisting}[language=bash]
    showyourwork setup ${GITHUB_USER}/${GITHUB-REPO}
  \end{lstlisting}
and create the related repo on github (follow the instruction on screen - you can add the caching support on Zenodo and the Overleaf connection also in a second step)
A working \texttt{environment.yml} for the conda environment is:
  \begin{lstlisting}[language=bash]
    channels:
      - conda-forge
      - defaults
    dependencies:
      - numpy=1.21
      - pip=25.1.1
      - python=3.10
      - pip:
        - matplotlib==3.10
  \end{lstlisting}
You can then build first your paper locally
  \begin{lstlisting}[language=bash]
    showyourwork build
  \end{lstlisting} 
and check the resulting ms.pdf file in the root directory for the final result.

\subsection{Remote build on github}
In order to build it on github with github actions you need first to include/substitute in the files \texttt{build.yml} and \texttt{build-pull-request.yml} under the directory \texttt{.github/workflows} the following lines:
  \begin{lstlisting}[language=xml]
    - name: Build the article PDF
      id: build
      with:
        showyourwork-spec: git+https://github.com/showyourwork/showyourwork
      uses: showyourwork/showyourwork-action@main
      env:
        SANDBOX_TOKEN: ${{ secrets.SANDBOX_TOKEN }}
        OVERLEAF_TOKEN: ${{ secrets.OVERLEAF_TOKEN }}
  \end{lstlisting}
then you can \texttt{git add} the changed files, commit it and push it to the remote repository.

\section{Adding a figure}
\subsection{Simple figure}
\showyourwork does not expect you to provide directly a figure (in fact it gives an error if you do).
It expects instead a script to generate the plot through the \texttt{script} command and, after running it, it looks for the figure obtained with it.
Fig.~\ref{fig:random_numbers} is an example. The script \texttt{randomnumbers.py} is placed in the \texttt{src/scripts/} directory and called in the first line of the figure definition. After that, the figure is included normally from the predefined path.
\begin{lstlisting}[language=TeX]
\begin{figure}
    \script{random_numbers.py}
    \begin{centering}
        \includegraphics[width=\linewidth]{figures/random_numbers.pdf}
        \caption{
            Plot showing a bunch of random numbers.
        }
        \label{fig:random_numbers}
    \end{centering}
\end{figure}
\end{lstlisting}
The script is generating and plotting some random numbers using the \texttt{numpy random} package 
\begin{lstlisting}[language=python]
import matplotlib.pyplot as plt
import numpy as np
import paths

# Generate some data
random_numbers = np.random.randn(100, 10)

# Plot and save
fig = plt.figure(figsize=(7, 6))
plt.plot(random_numbers, 'k.')
plt.xlabel("x")
plt.ylabel("y")
fig.savefig(paths.figures / "random_numbers.pdf", bbox_inches="tight", dpi=300)
\end{lstlisting}

\begin{figure}
    \script{random_numbers.py}
    \begin{centering}
        \includegraphics[width=\linewidth]{figures/random_numbers.pdf}
        \caption{
            Plot showing a bunch of random numbers.
        }
        \label{fig:random_numbers}
    \end{centering}
\end{figure}

\subsection{Static figure}
It is possible that some figures are not generated from a script, i.e. an hand drawn figure or a figure from another paper. In that case \texttt{showyouwork!} provides a static directory under \texttt{src/static} where any static content can be added. In this case the figure is defined normally in \LaTeX, but the location of the figure is always within the figures folder (\showyourwork is copying it under the wood from the static directory to the \LaTeX figures directory).
\begin{lstlisting}[language=TeX]
\begin{figure}
    \begin{centering}
        \includegraphics[width=\linewidth]{figures/usmlogo.pdf}
        \caption{
            USM Logo.
        }
        \label{fig:usm_logo}
    \end{centering}
\end{figure}
\end{lstlisting}

\begin{figure}
    \begin{centering}
        \includegraphics[width=\linewidth]{figures/usmlogo.pdf}
        \caption{
            USM Logo.
        }
        \label{fig:usm_logo}
    \end{centering}
\end{figure}

\section{Zenodo integration}

\subsection{Static datasets}
If your workflow depends on data that cannot be programmatically generated (e.g. data collected from a telescope), that data should be made available to anyone trying to reproduce your results. Instead of committing the dataset directly to the repository, one can archive it on an online open-access file-hosting service (like Zenodo, for which \showyourwork does all the communicating back-and-forth for you). All you need to do is specify the ID of the (public) archive and some information about the files your workflow needs in the \texttt{showyourwork.yml} config file.

\subsection{Dynamic datasets}
\showyourwork can cache the results of intermediate steps in your pipeline on Zenodo or Zenodo Sandbox.
This is useful for workflows that need running expensive simulations, etc., that a reader may not want to rerun.
It's also useful for builds on GitHub Actions, which has limited compute resources.

The way \showyourwork deals with these cases is to cache these lengthy computations on Zenodo alongside a record of all the inputs that went into generating the cached output. If, on subsequent runs of the workflow, the inputs remain unchanged, \showyourwork will simply download the cached results from Zenodo, maintaining the guarantee that the output you get follows deterministically from the given inputs.

\subsubsection{Set-up the Zenodo integration}
By default, caching takes place on Zenodo Sandbox, which is equal to Zenodo in all respects except that records on that service are temporary. This makes it perfect for caching intermediate results during the development cycle, where things are likely to change a lot and you may not want to assign a static, permanent DOI with any particular dataset.

\showyourwork needs access to an API token to communicate with Zenodo Sandbox.
You can generate it by clicking \href{https://sandbox.zenodo.org/account/settings/applications/tokens/new}{here}.
Name the token something informative and make sure to give it \texttt{deposit:actions} and \texttt{deposit:write} permissions.
Copy the token and store it somewhere secure.

Then, on your local computer, create an environment variable called \texttt{\$SANDBOX\_TOKEN} with value equal to the API token you just generated.
You can either do this manually: \texttt{export SANDBOX\_TOKEN=YYYYYY} or by adding that line to your shell config file (.bashrc, .zshrc, etc.) and re-starting your session.
In order for \showyourwork to have access to Zenodo Sandbox when running on GitHub Actions, you'll also have to provide this value as a secret with name \texttt{SANDBOX\_TOKEN}.

If you've done all that, the next time you create a new article repository using \texttt{showyourwork setup}, pass the \texttt{--cache} option and \showyourwork will automatically create a Zenodo Sandbox draft deposit which it will use to cache your intermediate results. Note that you can also manually create a draft deposit by running \texttt{showyourwork cache create} after you created your article repository.

\subsubsection{Intermediate results}

Earlier, we mentioned that the Zenodo integration allows users to cache intermediate results in their workflow.
But what is an \textit{intermediate result}?
The standard procedure for generating figures using \showyourwork is to define a figure script that generates the figure output.
There is no intermediate step. We simply go from figure script to figure output.

However, if our figure script involves some expensive simulation, every time we change anything in that script, \showyourwork will attempt to re-run the entire computation when asked to build your article.
This is good for reproducibility but it is extremely wasteful in cases where we wish to tweak some aspect of the plot, like the color of a line.

To avoid this, we can split our script into two: one that runs the simulation and saves the results, and one that loads the results and plots them.

\subsubsection{A DustPy simulation}

Consider a workflow that needs to run a DustPy simulation to generate a figure.
We would like to streamline our workflow by decoupling the plotting step from the simulation step.
We can do this by introducing two scripts in the \texttt{src/scripts} directory.
A first one \texttt{simulation.py} that runs and saves the result of the simulation. 

\begin{lstlisting}[language=python, caption=simulations.py]
from dustpy import Simulation, constants
import paths

sim = Simulation()
sim.initialize()

sim.writer.datadir = paths.data
sim.writer.overwrite = True

sim.run()
\end{lstlisting}

And a second one \texttt{figure.py} that loads the results and plot the figure:

\begin{lstlisting}[language=python, caption=figure.py]
import numpy as np
import matplotlib.pyplot as plt
import paths
from dustpy import hdf5writer

cm_to_au = 6.684587e-14

#Load the data
writer = hdf5writer()
writer.datadir = paths.data
data = writer.read.output(21)

# Plot the results
fig, ax = plt.subplots(2, layout='tight')
ax[0].semilogy(data.grid.r*cm_to_au, data.gas.Sigma)
ax[0].set_title('Final gas distribution')
ax[0].set_xlabel('R [au]')
ax[0].set_ylabel(r'$\\Sigma_g$ [g/cm$^{-2}$]')
ax[0].set_ylim(1.e-2,1e3)
ax[0].set_xlim(0,400)
ax[1].semilogy(data.grid.r*cm_to_au, data.dust.Sigma)
ax[1].set_title('Final dust distribution')
ax[1].set_xlabel('R [au]')
ax[1].set_ylabel(r'$\\Sigma_D$ [g/cm$^{-2}$]')
ax[1].set_ylim(1.e-4,1e1)
ax[1].set_xlim(0,400)
fig.savefig(paths.figures / "figure.pdf")
\end{lstlisting}

which is then called by \LaTeX to plot the figure on the paper

\begin{lstlisting}[language=TeX]
\begin{figure}
    \script{figure.py}
    \begin{centering}
        \includegraphics[width=\linewidth]{figures/figure.pdf}
        \caption{
            Plot showing the result of a DustPy simulation.
        }
        \label{fig:simulation_dustpy}
    \end{centering}
\end{figure}
\end{lstlisting}

\begin{figure}
    \script{figure.py}
    \begin{centering}
        \includegraphics[width=\linewidth]{figures/figure.pdf}
        \caption{
            Plot showing the result of a DustPy simulation.
        }
        \label{fig:simulation_dustpy}
    \end{centering}
\end{figure}

Our workflow is now separable: changes to \texttt{figure.py} will not result in the re-execution of the simulation, as they are merely plotting changes.
The simulation will only be re-executed if we change something in \texttt{simulation.py}, like the input arguments to our simulation function.

In order to get this all to work, we need to tell \showyourwork that:
\begin{enumerate}
\item the script \texttt{figure.py} has a dependency called \texttt{data0021.hdf5}
\item the dependency \texttt{data0021.hdf5} can be generated by running the script \texttt{simulation.py}. 
\end{enumerate}

We accomplish this by

\begin{enumerate}

\item editing the config file \texttt{showyourwork.yml}

\begin{lstlisting}[language=bash]
dependencies:
  src/scripts/figure.py:
     - src/data/data0021.hdf5
\end{lstlisting}

\item adding a custom rule to our \texttt{Snakefile}

\begin{lstlisting}[language=bash]
rule simulation:
    output:
        "src/data/data0021.hdf5"
    script:
        "src/scripts/simulation.py"
\end{lstlisting}

\end{enumerate}

\subsubsection{Caching the intermediate result}

The workflow above is now separable, but we are still not caching anything.
If we commit and push it to GitHub, the runner will still have to execute \texttt{simulation.py} in order to generate \texttt{simulation.dat}.
The same goes for third-party users who have cloned your repository.
Adding caching functionality can be done by adding a single line to the \texttt{Snakefile}:

\begin{lstlisting}[language=bash]
rule simulation:
    output:
        "src/data/data0021.hdf5"
    cache:
        True
    script:
        "src/scripts/simulation.py"
\end{lstlisting}

which tells \showyourwork to cache the output of that rule (\texttt{simulation.dat}). 
Normally, if we were just running this in a regular Snakemake pipeline, this would result in the data file getting cached in some local hidden folder.
The next time you run your workflow, Snakemake will check to see if any of the inputs to the simulation rule changed and, if not, it will restore \texttt{simulation.dat} from the cache (if it is needed).

\showyourwork builds on this functionality by also caching the file \texttt{simulation.dat} on Zenodo Sandbox, allowing the results to be restored on any computer running your workflow (as long as they have the correct \texttt{SANDBOX\_TOKEN}).
This means that, provided you have run your workflow locally first, the runner on GitHub Actions will never have to execute \texttt{simulation.py}, as it can just download the result from Zenodo Sandbox.
Recall that this procedure still guarantees that you will get the same result as if you had run your entire simulation (provided your workflow is deterministic), since a cache is only restored if none of the upstream inputs to a rule have changed.

The cached files (and the hashes of the rule inputs) are stored in a Zenodo Sandbox deposit draft with concept ID specified in your zenodo.yml config file. If you navigate to Zenodo Sandbox in your browser and log in, you should see a draft with a title like Data for user/repo [main], where user/repo is your repository slug and main is the current branch. At any given time, you can only have one draft per deposit, so if you change any of the inputs to your rule (e.g., if you change the file simulation.py), the draft will get overwritten with a new version of the cache. Note, also, that drafts are private: only users with access to your account can see their files.

If you switch branches, or if you set up a repository without caching functionality and would like to add it, you can create a new Zenodo Sandbox deposit for the current branch by running

\begin{lstlisting}[language=bash]
showyourwork cache create
\end{lstlisting}

\subsubsection{Snakemake}

Under the hood, \showyourwork is essentially a wrapper around Snakemake.
The code builds the article PDF by parsing the i\texttt{showyourwork.yml} config file and the \texttt{ms.tex} manuscript to build the computational graph for the workflow, identifying which scripts it needs to execute and which datasets it needs to download to produce all the figures in the article.

If your article consists only of text and figures that can be generated by running lightweight scripts, you probably don't need to worry about any of this.
But for certain use cases, it can be convenient to extend or even override some of the \showyourwork functionality by defining custom Snakemake rules.

Every \showyourwork article repository is instantiated with a blank \texttt{Snakefile} at the repository root.
This file gets included at the start of the main (build) step of the workflow and it can be used to define custom rules or to run custom python code during the workflow.

Snakefiles are, at their core, Python scripts with a little extra functionality (i.e. any valid Python script is also a valid Snakefile)
However, the main thing you probably want to use the Snakefile for is to define custom rules for your workflow.
Snakefile rules tell Snakemake how to generate an output file from given input files, much like rules in a classic \texttt{Makefile}.
Snakemake rules usually look something like this:

\begin{lstlisting}[language=bash, caption=Snakemake]
rule simulation:
    input:
        "dataset1.dat",
        "dataset2.dat"
    output:
        "results.dat"
    conda:
        "environment.yml"
    params:
        seed=42,
        iterations=1000,
        mode="fast"
    script:
        "src/scripts/run_simulation.py"
\end{lstlisting}
In this example, we have defined a rule called simulation, which tells Snakemake how to produce the output file results.dat.
Specifically, this file can be generated by running the script \texttt{src/scripts/run\_simulation.py} in an isolated conda environment with specs given in \texttt{environment.yml}.
The rule also tells Snakemake that the files \texttt{dataset1.dat} and \texttt{dataset2.dat} are dependencies of \texttt{results.dat}, meaning that the rule cannot be executed if those files are not present (and there is no other Snakemake rule capable of generating them) and that whenever either of those two files is modified, this rule will be re-executed the next time the workflow runs in order to keep \texttt{results.dat} up to date with its inputs.
Finally, the rule specifies three parameters \texttt{params}, which can be accessed within the script via the \texttt{snakemake.params} dictionary (e.g., \texttt{snakemake.params["seed"]}). Note that there is no need to explicitly import snakemake within \texttt{run\_simulation.py}, as it gets automagically inserted into the namespace.

We can change our previous example to include some input parameters directly from Snakemake
\begin{lstlisting}[language=bash, caption=Snakemake DustPy]
rule simulation:
    output:
        "src/data/data{group}.hdf5"
    conda:
        "environment.yml"
    cache:
        True
    params:
        v_frag = 1.,
        rho_dust = 2.,
        alpha = 5.e-4,
        stellar_mass = 0.1,
        dust_to_gas_ratio = 0.01,
        disk_mass = 0.1
    script:
        "src/scripts/simulation.py"
\end{lstlisting}
\begin{lstlisting}[language=python, caption=simulations.py]
from dustpy import Simulation, constants
import paths

sim = Simulation()
sim.initialize()

sim.dust.v.frag = snakemake.params["v_frag"]
sim.dust.rhos = snakemake.params["rho_dust"]
sim.gas.alpha = snakemake.params["alpha"]
sim.star.M = snakemake.params["stellar_mass"]*constants.M_sun
sim.dust.eps = snakemake.params["dust_to_gas_ratio"]
sim.gas.Mdisk = snakemake.params["disk_mass"]*constants.M_sun

sim.writer.datadir = paths.data
sim.writer.overwrite = True

sim.run()
\end{lstlisting}

The argument to the script key must be a Python script. If your script is in a different language, you can instead pass the shell key and provide a string containing the shell command Snakemake should execute to produce the output file, e.g., \texttt{jupyter execute notebook.ipynb}.
If you do that, remember to include the script (\texttt{notebook.ipynb}) as an explicit input to your rule so that Snakemake can track dependencies properly.

Input files and parameters can be provided as functions, adding another layer of flexibility to your workflow. Rules can also be declared within for loops, if statements, etc. For the full list of features, please refer to the Snakemake documentation.

Another use case for custom rules is the definition of dynamic variables in the \LaTeX manuscript.
For example, say I have a script called \texttt{age\_of\_universe.py} that infers the age of the universe from some cosmological dataset:

\begin{lstlisting}[language=python, caption=Python age of universe]

import paths
from my_awesome_code import get_age_of_universe

# Load the data
dataset = paths.data / "planck.dat"

# Compute the age
age = get_age_of_universe(dataset)

# Write it to disk
with open(paths.output / "age_of_universe.txt", "w") as f:
    print(f"{age:.3f}", file=f)
\end{lstlisting}

I would like to report this age in the text of my article, but I want to avoid having to re-type it in every time I make changes to my workflow that affect this quantity.
We can easily automate this by defining a custom Snakemake rule:

\begin{lstlisting}[language=python, caption=Snakefile age of universe]
rule age_of_universe:
    input:
        "src/data/planck.dat"
    output:
        "src/tex/output/age_of_universe.txt"
    script:
        "src/scripts/age_of_universe.py"
\end{lstlisting}
And in the \LaTeX file:
\begin{lstlisting}[language=tex, caption=TeX age of universe]
Based on a detailed analysis of Planck observations of the cosmic microwave background, we have determined the age of the universe to be \variable{output/age_of_universe.txt} Gyr.
\end{lstlisting}
This functionality can easily be adapted to automatically populate tables in your article or anything else that can be generated programmatically from your workflow. 
Note that \showyourwork automatically parses calls to \texttt{variable} statements and adds their arguments as explicit dependencies of the manuscript, so that any changes to these files will trigger a re-run of the compile step. 

\section{Conclusions}

\begin{acknowledgements}
\end{acknowledgements}

\bibliography{bib} % your references Yourfile.bib

\end{document}
